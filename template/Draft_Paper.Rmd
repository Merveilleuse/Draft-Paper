--- 
# IMPORTANT: Change settings here, but DO NOT change the spacing. 
# Remove comments and add values where applicable. 
# The descriptions below should be self-explanatory
title: "Comparing rolling period forecasts of Facebooks' Prophet model to an ARIMA model: A Diebold-Mariano evaluation of the FTSE/JSE Top40 Index"
subtitle: "A Diebold-Mariano Evaluation of the FTSE/JSE Top40 Index"
Author: "Marvelous Mubenesha"  # First Author
Student: "MBNMAR005"
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 5 # Adjust default figure sizes. This can also be done in the chunks of the text
    fig_height: 4
abstract: |
  Facebook's data science team open-sourced Prophet, a package that allows analysts to forecast a wide range of business time series at-scale. Prophet employs intensive Bayesian modelling in two tiers. Purely through MAP parameter estimation, and in a quasi-Bayesian form through an automated forecast evaluation that enables analyst to improve a forecasting model if it underperforms when compared to other traditional models. This paper assesses the predictive accuracy of Prophets' forecasts to those of an ARIMA model that was identified using the Box-Jenkins methodology. This is achieved through a Diebold-Mariano evaluation of the rolling period forecast errors of returns on the FTSE/JSE Top40 Index across daily, weekly and monthly time horizons. The results of the study suggest that there is insufficient evidence to conclude that the forecasting models have unequal predictive ability within the scope of the FTSE/JSE Top40 Index. 
---
<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf. These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

```

<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction\label{Introduction}

In business, including that involving the stock market, analysts require a large number of time series forecasts to inform decision making. The challenge with existing reliable approaches to forecasting time series data are that the models require a considerable background in statistics to build and adapt to prevailing market conditions when needed. Several authors have recommended automatic forecasting, which refers to algorithms that can automatically forecast a large number of univariate time series. However, the forecasts generated by these methods have been found to be brittle as well as inflexible in allowing for prior information to be incorporated into the forecasting model [@taylor2017forecasting]. In February of 2017, Facebook's Core Datascience team open sourced Prophet, a time series forecasting tool with unique features that enable "forecasting-at-scale". Forecasting-at-scale is a term coined by the data science team which they define as, "an approach that allows a large number of analysts to forecast a large number and variety of business time series" [@taylor2017forecasting]. It has the added advantage of being less 'expensive'
than other alternatives. In addition, it is specifically preferable over ARIMA models because of its non-linearity, flexibility and ability to accomodate varying time intervals [@taylor2017forecasting].

The objective of this paper is to compare the rolling period forecasts generated by Prophet (which uses automated, intensive Bayesian Modelling to 'forecast-at-scale'), to those obtained from an ARIMA model (constructed through the Box-Jenkins methodology),
through a Diebold-Mariano evaluation of the FTSE/JSE Top40 Index. The study is particularly useful because analysts from a wide background can reliably forecast stock price returns automatically, and incorporate their prior knowledge in the forecasting model, without a wholesome understanding of the statistical intricacies involved. It is hoped that this could create opportunities for automated invesment mechanisms.

The paper is organized as follows. A review of literature relating to stock price forecasting with ARIMA models and other alternative approaches is introduced in section 2.1 to give the reader background information on existing research relating to the subject matter. Thereafter, theory relating to the mathematical formulation and estimation of an ARIMA and Prophet model is included in sections 2.2 and 2.3 respectively. Subsequently, in section 2.4, the theoretical motivation and mathematical formulation of the Diebold-Mariano test is introduced as a means of comparing the predictive accuracy of two prediction models. Information relating to the data that was used in this study is contained in section 3, after which, the methodology used to answer the research question is described in section 4. Section 5, contains the results obtained when the methodology was executed, whilst section 6 includes a discussion of the results. The discussion includes a response to the research question as well as some useful insights from the results. Furthermore, it highlights some recommendations for further areas of research based on the findings of the paper. Lastly, the conclusion in section 7 summarizes the results of the study relative to the main objective of the paper.   

# Background 
In this section we will briefly review literature that relates to the comparison of different approaches to forecasting stock returns. This will include both traditional approaches as well as relatively new methods such as automatic forecasting, machine learning techniques and quasi-Bayesian forms which incorporate analysts' prior information. The theoretical and mathematical formulation of an ARIMA forecasting model is  then briefly introduced. Thereafter, the theoretical framework and mathematical formulation of Facebooks' Prophet forecasting tool is discussed. Specific attention is drawn to Prophets distinguising features to give the reader an understanding of the value that this forecasting technique can potentially add to stock price prediction. The background information is concluded with an introduction to the Diebold-Mariano Evaluation as a suitable framework to formally compare the predictive accuracy of two forecasting models.

##Literature 
###Forecasting stock prices using the ARIMA model

ARIMA models have been widely used as a standard model to forecast financial data and have been shown to yield forecasting errors that lie within acceptable bounds [@adebiyi2014comparison]. @adebiyi2014comparison used the Box-Jenkins methodology to build short-term stock price prediction models for stocks on the New York Stock Exchange(NYSE) and the Nigerian Stock Exchange(NSE). Their results showed that the predictive power of the ARIMA model was satisfactory based on forecast error diagnostics.

ARIMA models rely on the assumption that residuals are homoskedastic(they have a constant variance) and normally distributed. However, the residual errors of some financial data display heteroskedasticity making GARCH models more applicable. This theory is backed by a study conducted by @Muten2014 who compared the ability of ARIMA and GARCH models to forecast stock prices on the Zimbabwean Stock Exchange (ZSE). They found that the GARCH model outperforms the ARIMA model which suggests that incorporating heteroskedasticity of the residual errors improves the forecasting ability of the model. This is a case in point for emerging market stocks. The researchers noted that poor liquidity in the market could be a cause of the results they observed [@Muten2014].

###Forecasting stock prices using alternative methods: The case of Artificial Neural Networks and Hybrid Models

Though the ARIMA model is tractable given that it is simple, interpretable and yields forecasts that are significantly accurate when compared to other methods, it has its limitations. The most popular being its inability to capture non-linear patterns in data, even after its evolution from the standard form to more adaptable formulations [@moreno2011artificial]. Over the past two to three decades with the evolution of computational power and statistical advancement, other stock price prediction methods have been proposed, the most prominent being a machine learning approach called Artificial Neural Networks(ANNs) [@lin2009short]. Also popular amongst the new stock price forecasting approaches are hybrids of existing methods that incorporate the benefits of different approaches.  

An Artificial Neural Networks (ANNs) is a multi-layered perceptron with nodes that simulate the action of neurons as illustrated in  figure 1.  
![](ANN.png)  
**Figure 1 : Illustration of an Artificial neural network** [@tanikic2012artificial]  
Formally, an ANN consists of a sorted triple $(K, A, \omega)$. $K$ is a set representing the multiple levels of the network i.e. input, hidden and output levels. A is a set of pairs that represents the index for the estimated parameter at the $i^{th}$ node of the $k^{th}$ level in the network. This is illustrated by the curved down arrow in Figure 1 which points to an enlarged segment of the $i^{th}$ node in the $k^{th}$ level i.e. $a_{i,k} \in A$. Lastly, $\omega$ represents a function that defines the weights ($\omega_{i,r}$) of connections between nodes that interact across adjacent levels [@kriesel2007brief]. Artificial Neural networks apply iterated optimization of model parameters across the network in the form of weights conditional on observed values to learn [@segaran2007programming]. Several studies have compared ARIMA model forecasts to ANN and their conclusions are contradictory.  

Researchers have found that the performance of either method depends on the nature of the data and forecasting problem [@kihoro2004seasonal]. Stock price data is proposed to be nonlinear which suggests that nonlinear approaches have the potential to produce better forecasts than linear models. Furthermore, ANNs make no assumptions about the distribution of the errors as compared to the linear ARIMA model [@adebiyi2014comparison]. @adebiyi2014comparison compared NYSE stock index forecasts of an ARIMA model to those of an ANN and found that the forecasting accuracy of the ANN model was superior to that of the ARIMA model. It is evident that ANN are preferred to ARIMA models as a model free, nonlinear alternative. However, the model construction of an ANN requires trial and error to initialize parameter estimates and these parameters are not easily interpretable by analysts [@moreno2011artificial]. Researchers have found different ways to guide analysts in this respect. In 1996, @wang1996stock proposed an ARIMA-based ANN to forecast the medium-term price of the Taiwan Stock Exchange Weighted Stock Index (TSEWSI). They used the Box-Jenkins methodology to difference the series and then trained the data on a neural network with initialisations that were guided by their observations of the ARIMA model. Their hybrid model yielded forecasts that were comparably superior to the individual models used in isolation based on an analysis of the out-of-sample residual error diagnostics. @wang1996stock therefore concluded that the ARIMA-based Neural Network outperformed a Neural Network trained using raw stock price data [@wang1996stock]. @zhang2009stock used a combination of the backpropagation algorithm from Neural Networks with Improved Bacterial Chemotaxis Optimization (IBCO) to build a model that forecasts the S&P 500 stock index by minimizing the mean square error. Model forecasts were evaluated through simulation experiments and the results led to the conclusion that the hybrid model produced superior forecasts [@zhang2009stock]. This study further highlighted the potential that nonlinear approaches have in forecasting stock prices. An issue that arises with such methods is the complexity of the proposed models which limits the flexibility of unseasoned analysts to adjust model parameters as a way of improving forecasting accuracy. As we will see, Prophet elegantly deals with this issue in the form of a nonlinear, Generalized Additive Model (GAM).

###Quasi-Bayesian forecasting methods that incorporate an analysts' knowledge 

The stock price forecasting approaches considered so far purely apply technical data analysis methods to generate stock price forecasting models. However, studies that have compared pure technical approaches to those that incorporate an analysts knowledge in a quasi-Bayesian form have been shown to be superior at predicting market prices [@givoly1984quality \& @guerard1989combining]. The first instance of combining time-series model forecasts and an analysts forecasts to obtain superior forecasts of a stocks annual earnings can be dated to 1989. @guerard1989combining used an additive model to combine consensus security analyst forecasts from the S&P Annual Earnings forecaster and annual earnings forecasts generated by an ARIMA model with a nonzero mean. The combined model that was estimated using ordinary least squares reduced the mean square error of the time series and analysts forecasts from 1.28 and 1.27, respectively to 1.04. These results suggest that analysts can reduce forecasting errors by combining technical methods with expertise developed through market knowledge [@guerard1989combining]. @zahedi2015application applied the same overarching principle when they used principle component analysis to determine an appropriate input variable which they then used to train an ANN in an attempt to predict stock prices on the Tehran Stock Exchange. Their model yielded reduced forecasting errors and performed better than the pure ANN. These results further reiterate the potential of incorporating an analysts knowledge to improve stock price forecasts, in both linear and nonlinear models.   

## ARIMA model formulation

The ARIMA model is a generalisation of Autoregressive Moving Average (ARMA) models which combine autoregression and moving average features [@box1970time]. In the context of returns, the ARIMA formulation for the return at time index $t$, $r_t$, is given by,
$$  r_t = \phi_1 r_{t-1} + \phi_2 r_{t-2} + ...+ \phi_p r_{t-p} + \epsilon_t +
        \psi_1 \epsilon_{t-1} + \psi_2 \epsilon_{t-2} + ... +\psi_q \epsilon_{t-q} $$where:  
$\bullet$  $\phi_i$ and $\psi_j$ are the parameters to be estimated  
$\bullet$  $r_{t-k}$ is the $k^{th}$ lagged return   
$\bullet$  $\epsilon_t$ is the error term at time $t$ which is assumed to be white noise  
$\bullet$  $\epsilon_{t-k}$ is the $k^{th}$ lagged error   
$\bullet$  $p$ is the order of the autoregressive component (dependence on history of $r_t$) and  
$\bullet$  $q$ is the order of the moving average component (dependence on history of $\epsilon_t$).  

The ARIMA model will be used as a standard forecasting method which Prophet will be compared against. Model building and parameter estimation will follow the approach outlined by @box1970time and is further discussed in the methodology


## Prophet model formulation and estimation

The challenge with many forecasting methods such as the Box-Jenkins methodology and machine learning approaches discussed in the literature review are that they usually require a sufficient statistical background to construct and modify if necessary. Furthermore, some of these approaches tend to be inflexible with respect to incorporating prior information. In some instances, such as with ANN, incorporating prior information can be partially achieved through initializing parameter estimates. However, an analyst with limited statistical training can have difficulty interpreting and thus modifying initial parameter estimates [@taylor2017forecasting].  
Prophet is an **automatic forecasting** tool that uses a Bayesian Generalized Additive model to generate time series forecasts. This is in comparison to conventional methods such as the linear stochastic dependence that exists in ARIMA models. Prophet combines a configurable model that includes an automated evaluation of forecasts with the interaction of an analyst in the loop [@taylor2017forecasting]. The model is configurable which allows an analyst to incorporate their knowledge of the behaviour of the series into the model building process through easily interpretable initial parameters that can be modified and interactive feedback when forecasts under-perform [@taylor2017forecasting]. 

Through this mechanism, a large number of forecasts can be reliably generated **automatically** with the flexibility of enabling an analyst to modify the model in-the-loop during model specification. The automated forecasting procedure with an analyst-in-the-loop is illustrated in Figure 2.  
  
  The first step of the forecasting procedure begins with the analyst simply specifying a general model (i.e. modelling). Prophet then goes into the automated process of estimating model parameters and performing forecast evaluation.  Automated forecast evaluation is undertaken by constructing baseline forecasts using methods such as the sample mean, ARIMA, exponential smoothing and naive estimates (e.g. last value or seasonal last value). Thereafter, simulated historical forecasting (SHF) errors are evaluated by comparing forecasts of the baseline methods and prophet to the observed historical values. SHF errors are forecast errors generated by random points in the history of a time series model. Prophets SHF errors that are relatively large compared to the baseline methods are then surfaced with visual illustrations of the results. The process then transitions from surface problems to the top left of the cycle in Figure 2 labelled analyst-in-the-loop. Here, the analyst can then visually inspect forecasts to identify issues and modify features of the Prophet model before it is re-estimated in the modelling stage. The loop is repeated until forecast evaluation surfaces no problems [@taylor2017forecasting].

![Figure 2](analyst in the loop.png){ width=80% }  
**Figure 2: Illustration of Prophets' automated forecasting procedure with an analyst in the loop** [@taylor2017forecasting]  

The interpretability of Prophets' model parameters stems from the mathematical formulation of the generalised additive model. The formulation posits that the series is generated by an additive, parametric function of time $r(t)$, defined by,
$$ r(t) = g(t) + s(t) +  h(t) + \epsilon_t.$$ The additive components include growth, seasonality and a component that adjusts for holidays as well as once-off events e.g. anticipated market shocks in the instance of financial time series.


Firstly, the growth component, $g(t)$, is modelled using a generalized form of the logistic population growth model and is of the form;  
$$g(t) = \frac{C(t)}{1+exp(-(k+\boldsymbol{a}(t)^T \delta(t-(b+\boldsymbol{a}(t)^T \gamma)))}$$  
where:  
$\bullet$   $C(t)$ represents the carrying capacity of the growth component and can be modelled using a polynomial function of time, the simplest being a constant or linear model.  
$\bullet$   $(k+\boldsymbol{a}(t)^T\delta)$ is the growth rate factor with the $\boldsymbol{a}(t)^T\delta$ term enabling the forecaster to choose where the growth rate changes( i.e change points) and   
$\bullet$   $(b+\boldsymbol{a}(t)^T \gamma)$ is the adjusted offset parameter.  
The growth component of the model has two useful features that allow the carrying capacity and growth rate of the model to vary with time. This enables an analyst to manually define when and how the growth rate changes at different change points [@taylor2017forecasting]. This feature is particularly useful for forecasting stock price data since analysts are able to incorporate market movements that lead to the growth rate either decreasing, increasing or becoming constant.     

Secondly, the seasonality component, $s(t)$ with periodicity $P$ is given by,
$$s(t) = \sum_{n = -N}^{N}c_n \exp(j\frac{2\pi nt}{P})$$

Yearly and weekly seasonality is modelled using the standard Fourier series. Analysts can thus use prior knowledge to account for the effects of periodicities they have observed seasonally.  
  
  
Lastly, $h(t)$ is the holiday and events component, a feature that ARIMA models are not adapted to. The holiday component enables analysts to incorporate shocks and once-off events that do not follow a periodic pattern but may have an effect on the price of a stock. Holidays and events are modelled using,  
  
$$ h(t) = \sum_{j = 1}^{L}\kappa_j \boldsymbol{1}(t \in D_j) \label{eqn5}
$$
Where, $\kappa$ is a normally distributed scaling factor and  $D_j$ is a set of past and future dates where holidays or events occur.  
  
  
Prophet translates model parameter estimation into a curve-fitting exercise by employing Maximum Apriori Posterior (MAP) estimation, a Bayesian approach to estimating optimal parameter values for the forecasting model. MAP estimation finds the maximum posterior estimates for the parameters by using the likelihood function and an apriori distribution to evaluate a posterior distribution which is then optimized to return point estimates of the parameters [@taylor2017forecasting]. 

##Diebold-Mariano evaluation
As is evident from sections 2.2 and 2.3, the modelling approach and assumptions of Prophet differ to those of an ARIMA model. Since the two methods differ, the Diebold-Mariano evaluation is preferred as a means of formally comparing the forecasting accuracy of the two models statistically. The Diebold-Mariano evaluation is a **model free** hypothesis test for the equal predictive accuracy of two forecasting methods, referred to as model 1 and model 2. It is applicable to a wide range of situations from forecast residuals that are non-Gaussian, asymmetric loss functions, serially correlated errors and multi-period forecasts [@Mariano2000]. The Diebold-Mariano test (DM test) operates by evaluating the forecast errors for both model 1 and model 2 (i.e $e_{t_1}$ and $e_{t_2}$) at a loss function $g(\bullet)$. The loss function can be choosen flexibly as long as it is zero when the error is zero, is strictly positive for all values on the real line and, it increases with an increase in the absolute value of the error size. The loss differential between two forecasts at time $t$ is then defined by, $$ d_t =  g(e_{t1}) - g(e_{t2})$$ for $t = (1, 2, ..., M)$ where $M$ is the total number of forecasts that have been generated from each model. We then test whether, $$ \mu = E[d_t] = 0 $$ by conducting the following hypothesis test;  
Null hypothesis: $$ E[d_t] = 0  \,\,\,\, \forall t$$   
Alternative hypothesis: $$ E[d_t] \neq 0 $$  
Test statistic: $$DM_{stat} = \frac{\sqrt M (\bar{d} - \mu)}{\sqrt{\hat{\gamma_d(0)}}} $$

$\bar{d}$ is the sample mean of the $M$ loss differentials and $\frac{\hat{\gamma_d(0)}}{M}$ is the asymptotic variance of  ($\bar{d} - \mu$) with $\hat{\gamma_d(k)}$ representing the autocovariance of the loss differential series at lag $k=0$. Asymptotically, the $DM_{stat}$ has a standard normal distribution if the loss differential series is short memory and covariance stationary [@Mariano2000].  
There are two caveats to using the DM Test for the purposes of this paper. Firstly, the choice of the loss function depends on whether the forecast errors can be assumed to be symmetric or asymmetric. When the forecast errors are symmetric, a linear or quadratic loss function can be used to evaluate the loss differential. For forecast errors that are asymmetric, a loss fuction that satisfies the conditions outlined in the first part of this section can be used. Secondly, literature does not clearly stipulate the sample size range that is sufficient for the asymptotic distribution assumption to  hold. In light of this, relatively large sample sizes were used in this study and the DM test results are applied conservatively. 

#Data

The data set used throughout this paper comprises of the daily closing prices of the FTSE/JSE Top40 price index for the five year period from 31/07/2012 to 31/07/2017. This equates to a total of 1305 trading days excluding weekends and holidays. This period was chosen for its recency and to avoid exposing the results to the noise associated with the high volatility experienced in the stock market during the 2008 financial crisis. The aim is to compare the predictive accuracy of the two models under standard market conditions before other confounding factors can be closely analysed.  Figure 3 shows the actual realisations of the price index data which was sourced from Datastream.

```{r, echo=FALSE}
#Import, transform and plot data
library(dplyr)
library(readxl)
top40index <- read_excel("~/Honours_project/Draft-Paper/top40index.xlsx", 
                         col_types = c("date", "numeric"))
index <- top40index%>%distinct(date, .keep_all = TRUE) #Removing duplicate dates

plot(index, type = "l",
     main = "FTSE/JSE Top40 Index 07/2012 - 07/2017")
```
**Figure 3: Realisation of the FTSE/JSE Top40 Price Index over the period of study** 
  
The price index was transformed to log returns as a means of avoiding spurious regression issues which can be caused by the existence of unit roots in stock price data.

In this paper, the **log return** (which will be used interchangeably with **return**), over the period $[t,t+1]$ is denoted by $r_t$, and was calculated by evaluating;  
$$
r_t = log(\frac{P_{t+1}}{P_t})  \label{eq1}
$$  
Where $P_t$ and $P_{t+1}$ represent the price of the index at time $t$ and $t+1$ respectively.

#Methodology

Preliminary data processing was done to clean and transform the data before formally testing for outliers. The data was then split into in-sample and out-of-sample periods. As was mentioned in section 2.4, literature does not clearly stipulate what sample size is sufficient for the asymptotic distribution assumption to hold. In response to this, 20% of the available data was used as the out-of-sample period. The in-sample period comprises of 1044 trading days between 30 July 2012 to the 31 July 2016 whereas the out-of-sample period comprises of the trading days between 1 August 2016 and 31 July 2017. 

```{r, eval=FALSE}
# Outliers
boxplot(c(index[,2]), names = c("price index"), main = "Boxplot of Price Index")  #Comment : looks like there are some outliers eventhough outliers are 'relatively' clustered
log.returns <- CalculateReturns(as.ts(top40index[,2]), method = "log")[-1] 
boxplot(log.returns, names = c("log returns"), main = "Boxplot of Log Returns on the Price Index")

#Formal tests for Outliers in Time series --------------------------

library(tsoutliers)  # conducts multiple tests for outliers #Reference Chen and Liu;s as authors : https://stats.stackexchange.com/questions/104882/detecting-outliers-in-time-series-ls-ao-tc-using-tsoutliers-package-in-r-how
library(ggpubr)
log.returns.outlier.detection <- tsoutliers::tso(as.ts(log.returns),types = c("AO","IO","LS","TC","SLS"), maxit.iloop = 10)
log.return.outlier.detection  #Several outliers detected
#Further investigation shows that these outliers occur when the return is large in abs value, because this is due to natural market activity and the outliers do not reflect in the boxplot of the price index, the outliers have been kept in the data. See : log.returns[c(299,302,348,1144,1156,1540)]

```  
  
The in-sample data was used to identify the ARIMA forecasting model using the method outlined by @box1970time for building and estimating an ARIMA model.  
Thereafter, one-step rolling forecasts with re-estimation as outlined by @RJHyndman2014 were evaluated for an automated Prophet model and the ARIMA model that was identified using the Box-Jenkins methodology. This procedure was then repeated for a 5-step and 20-step forecast horizon in order to determine whether the performance of the models vary when estimating daily,weekly or monthly stock returns.

The forecasts generated above were then used to calculate **h-step rolling forecast errors** for both the ARIMA and Prophet model. For each time point $t$ in the out-of-sample period, the rolling forecast error is given by,  

$$ \hat{e_t} = r_t - \hat{r_t},$$  where $r_t$ is the actual return and $\hat{r_t}$ is the rolling forecast at time $t$.    


Summary statistics of the errors where used to compare the performance of the forecasting models before a formal statistical test was performed using the DM test with a linear and quadratic loss function. Using either a linear or quadratic loss function implicitly assumes that the forecast errors are symmetric [@Mariano2000]. This assumption is reasonable given the apparent symmetry in the distribution of forecast errors as is evident from the boxplots in Figure 5, section 5.2.

#Results
##Box-Jenkins methodology: ARIMA model identification and selection

The methodology as outlined in @box1970time was applied to the data through the following procedure. The stationarity of the time series was tested formally by performing an Augmented Dickey-Fuller test on the in-sample log returns data. The test yielded a p-value less than 1% which implies that we reject the null hypothesis which states that the in-sample returns series non-stationary.

The autocorrelation(ACF) and partial autocorrelation(PACF) functions in Figure 4 were used to identify candidate *ARIMA(p,d,q)* models to fit to the in-sample data. The results suggest that the second lag of both functions might be significantly different from zero. 
```{r in-sample and out of sample data import and log transformation , include=FALSE}
#Partitioning in-sample and out-of-sample data
library(PerformanceAnalytics)
in.sample.data <- index %>% filter(between(date, as.POSIXct("2012-07-31"), as.POSIXct("2016-07-31")))

oos.data <- index %>% filter(between(date, as.POSIXct("2016-07-29"), as.POSIXct("2017-07-31")))  #choose the 29th to be able to calc the first oos return

#Transforming data to log returns
in.samp.log.returns <- CalculateReturns(as.ts(in.sample.data[,2]), method = "log")[-1] 
oos.log.returns <- CalculateReturns(as.ts(oos.data[,2]), method = "log")[-1]

# Formally testing stationarity/Unit root test
library(tseries)   #for Augmented Dickey-Fuller test
adftest <- adf.test(in.samp.log.returns) # p < 0.01 therefore we reject the null that unit root exists 


```

```{r acf_and_pacf_plot, fig.width=6.7, fig.height=3.5, fig.align="center"}
#PACF and ACF
par(mfrow = c(1,2))
plot1 <- acf(in.samp.log.returns, main = "ACF of log returns", ylab="")  #ma(2)
plot2 <- pacf(in.samp.log.returns, main = "PACF of log returns",ylab="")  #ar(2), ar(30)
par(mfrow = c(1,1))
```
**Figure 4 : ACF and PACF plots for in-sample data**  

The candidate models that were fit to the in-sample data are shown in Table 1 with their respective AIC values. The $ARIMA(2,0,2)$ model had the lowest AIC and was thus selected as the ARIMA forecasting model.  


**Table 1: AIC for candidate ARIMA models**
```{r AIC Table for candidate ARIMA Models, results = 'asis'}

library(xtable)

candidate <- c("(0,0,0)","(2,0,0)","(0,0,2)","(2,0,2)")
aic.values <- c(-8804,-8808,-8808,-8817)

aic.mat <- matrix(data = c(candidate,aic.values),ncol = 2)
dimnames(aic.mat) <- list(c(" "," "," "," "),   #row names
                          c("ARIMA(p,d,q) model","AIC"))  #column names
data = aic.mat %>% tbl_df()


table <- xtable(data)
  print.xtable(table, 
             # tabular.environment = "longtable",
             floating = TRUE,
             table.placement = 'H', 
             # scalebox = 0.3, 
             comment = FALSE,
             include.rownames = getOption("xtable.include.rownames", FALSE) #exclude row number
             )

```
## Forecast error evaluation

The h-step ahead rolling period forecasts for the $ARIMA(2,0,2)$ and Prophet models yielded forecast errors whose distribution is shown in figure 5. The distribution across different time horizons for the ARIMA and Prophet models appear relatively similar. All six distributions are symmertrical about a mean of 0 and a spread of 0.02. The presence of outliers also appears to be consistent across the different models **and** forecasting horizons eventhough we can observe an increasing trend in the maximum values as the time horizon increases.  


\begin{figure}
```{r box_plot, fig.width=6.5, fig.height=4.0, include=TRUE,results="hide",fig.align='center'}
fore_res_1 <- read.table("CopyOf1 step ahead results.txt") 
fore_res_5 <- read.table("CopyOf5 step ahead results.txt")
fore_res_20 <- read.table("CopyOf20 step ahead results.txt")


library(plotrix)
par(mfrow=c(1,1))

names = c("Arima(h = 1)","Prophet(h = 1)",
          "Arima(h = 5)","Prophet(h = 5)",
          "Arima(h = 20)","Prophet(h = 20)")

boxplot(fore_res_1$error1, fore_res_1$error2,
        fore_res_5$error1,fore_res_5$error2,
        fore_res_20$error1,fore_res_20$error2,
        main = "Rolling Period Forecast Errors",xlab = "",xaxt = "n")
staxlab(1,1:6,names, srt = 45,cex = 1)


```
\end{figure}
*Figure 5: Boxplot illustrating distribution of rolling forecast errors for different time horizons, h*

### Forecast Error Statistics

Table 2 summarizes the forecast error statistics for both the ARIMA and Prophet model across the three different time horizons.  
For all forecast horizons, the ARIMA model appears to be overestimating returns. This is evident from the negative mean error(ME) across $h = (1,5,20)$. On the contrary, the Prophet model underestimates the forecasts for one-step and five-step ahead forecasting horizons. It then overstimates returns when forecasting twenty-steps ahead. Furthermore, the relative margin of the distance between the ME as the time horizons increasese is relatively larger for the Prophet model than it is for the ARIMA model. This could mean that the function of the ME against the forecast horizon is more volatile for the Prophet model than it is for the ARIMA model. This observation suggests that the Prophet model might have unstable forecasts across longer time horizons and could be inappropriate for use outside short term horizons in the domain of stock price data. 

**Table 2: Forecast error diagnostic statistics over different forecasting horizons**
```{r Forecast Error Statistics Table, results = 'asis'}

library(xtable)

c1 <- c("1"," ","5"," ","20"," ")
c2 <- rep(c("ARIMA","Prophet"),3)
c3 <- c('-0.0004110','0.0000176','-0.0003635','0.004445','-0.0001769','-0.0000406')
c4 <- c(0.0103,0.0104,0.0103,0.0103,0.0102,0.0102)
c5 <- c(0.007718,0.007749,0.007692,0.007709,0.007649,"0.007660")

error.stats.mat <- matrix(data = c(c1,c2,c3,c4,c5),ncol = 5)
dimnames(error.stats.mat) <- list(c(" "," "," "," "," "," "),   #row names
                          c("Forecast Horizon, h","Forecast Model"," ME ","RMSE","MAE"))  #column names
err.stat.data = error.stats.mat %>% tbl_df()


error.table <- xtable(err.stat.data)
  print.xtable(error.table, 
             # tabular.environment = "longtable",
             floating = TRUE,
             table.placement = 'H', 
             # scalebox = 0.3, 
             comment = FALSE,
             include.rownames = getOption("xtable.include.rownames", FALSE) #exclude row number
             
             )

```

The Root Mean Square Error (RMSE) across different forecast horizons and across both models are considerably close to each other in value relative to the other error statistics. These results suggest that the models possibly have the same forecasting accuracy. Furthermore, the ME and MAE results shown in Table 2 are comparably small which further suggests that the models possibly have the same forecasting accuracy. However, comparing the predictive accuracy of the two models using the error diagnostics alone is insufficient.

### Diebold-Mariano Evaluation

The observations made from Table 2 in section 5.2.1 suggest that the ARIMA and Prophet models have equal predictive accuracy. These assertions can be formally quantified through a Diebold-Mariano(DM) test which evaluates whether the models have equal predictive accuracy against the alternative hypothesis that one model has superior accuracy over the other. Table 3 reports the results obtained when the rolling forecast errors were formally compared against each other over different time horizons using either a linear or quadratic loss function. Both loss functions are appropriate for forecast errors that have an apparent symmetrical distribution (see figure 5) and were both used to gain insight into any discrepancies that might arise.

**Table 3: Results of the Diebold-Mariano hypothesis test for different loss functions**
```{r Table For Diebold Mariano Evaluation results, results = 'asis'}

library(xtable)

col1 <- c("1"," ","5"," ","20"," ")
col2 <- rep(c("Linear","Quadratic"),3)
col3 <- c(0.553,0.128,0.691,0.334,'0.660',0.296)


dm.mat <- matrix(data = c(col1,col2,col3),ncol = 3)
dimnames(dm.mat) <- list(c(" "," "," "," "," "," "),   #row names
                          c("Forecast Horizon, h","Loss Function , g(*)","p value"))  #column names
dm.data = dm.mat %>% tbl_df()


dm.table <- xtable(dm.data)
  print.xtable(dm.table, 
             # tabular.environment = "longtable",
             floating = TRUE,
             table.placement = 'H', 
             # scalebox = 0.3, 
             comment = FALSE,
             include.rownames = getOption("xtable.include.rownames", FALSE) #exclude row number
             
             )

```

The p-value across all the time horizons for either a linear or quadratic loss function suggest that we would fail to reject the null hypothesis. This implies that the predictive accuracy of the models could be equal. These results formally validate the observations made in section 5.2.1. 

#Discussion of results
The results of the study show that there is no significant evidence to conclude that Prophet generates superior forecasts for returns on the FTSE/JSE Top40 Index when compared against those of an ARIMA model when the Diebold-Mariano Test is used as a method of evaluation. It is worth noting that the p-value for the quadratic loss function is, on average, lower than that of the linear loss function. The sensitivity of the results to the nature of the loss function is worth exploring in the future. The results are consistent for daily, weekly and monthly forecasting horizons irregardless of the choice of the loss function.

Nevertheless, the study has flagged the possibility that, on average, the ARIMA model tends to overestimate forecasted returns on the index for the forecast horizons under consideration. This is contrary to Prophet, that, on average, underestimateD forecasted returns over daily and weekly time horizons. This information could be useful for an analyst engaged in **short-term** strategies since the choice of the forecasting model can reflect a particular sentiment or risk appetite. For example, if the analyst feels like prevailing returns are underpriced by the market, they might choose to use an ARIMA model, whereas an opposite sentiment could warrant the use of Prophet. A necessary caveat is the volatility of Prophet forecasting errors about the mean error and the ability to release exploitable gains in reality due to transaction costs.    
Furthermore, it is worth noting that the merits of Prophet may have not been fully explored in this study due to the use of transformed data and the choice of a forecasting horizon that excluded periods of high volatility. These areas create room for further study. Nonetheless, it is reassuring (and somewhat expected  because the ARIMA methodology is incorporated in the forecast evaluation of Prophet as a baseline method), that Prophet has performed as well as the ARIMA model. This observation could create room for the application of Prophet in circumstances where flexibility in the model formulation is desireable, or if the analyst has a limited statistical background.  

This study was confined to the analysis of predictive performance during general market conditions. Further research could explore the predictive ability of the models during different market conditions. For example, performance can be compared during bull and bear market conditions or during periods of high volatility. Additionally, further research can assess whether prophet would perform better on raw data that has not been transformed, since the model is built with growth and seasonality components. The use of which could lead to Prophet models that generate superior forecasts when compared against alternatives.  

Lastly, it is worth noting that the efficiency of the South African stock market is inconclusive. This means that forecasting the FTSE/JSE Top40 index might be a futile exercise if markets are efficient. However, there is room for traders with a lmited statistical background to exploit existing inefficiencies in some industries and market categories. This  


#Conclusion

The challenge of building models that generate superior stock return forecasts has led to widespread research in the field of quantitative analysis for decades, but the ARIMA model remains the standard against which to compare new innovations. This is because of its relative simplicity and ability to evolve into more complex applications e.g in the hybrid models considered in the literature review.  
Prophet has reduced the problem of estimating a time series model to a curve fittig exercise by defining an additive, parametric function of time. The functions' parameters are then estimated using Bayesian estimation methods after which the tool automatically executes forecast evaluation to optimize its predictive ability.  
The results of this study suggest that, using a Diebold-Mariano evaluation, the ARIMA and Prophet forecasting models do not have a significant difference in predictive accuracy across time horizons of up to a month. The implications of this are that analysts can then choose which model to use based on their needs without significantly compromising forecast  accuracy. The results also highlighted the possibility that ARIMA models tend to overestimate returns and thus using Prophet would imply a more conservative approach to predicting future returns, this could have widespread applications for investment strategies, one of which was highlighted above.  

 

# References  
